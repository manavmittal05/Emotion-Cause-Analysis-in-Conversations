{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/utkarsh/miniconda3/envs/pytorch_env/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle as pkl\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pandas as pd\n",
    "from transformers import DistilBertModel , DistilBertTokenizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import json \n",
    "def transform_conversations(data, is_test=False):\n",
    "    transformed_data = []\n",
    "    if is_test:\n",
    "        for conversation in data:\n",
    "            transformed_conversation = {\n",
    "                \"conversation_ID\": conversation[\"conversation_ID\"],\n",
    "                \"conversation\": []\n",
    "            }\n",
    "            for utterance in conversation[\"conversation\"]:\n",
    "                transformed_text = f\"{utterance['speaker']} said: {utterance['text']}\"\n",
    "                transformed_conversation[\"conversation\"].append({\n",
    "                    \"utterance_ID\": utterance[\"utterance_ID\"],\n",
    "                    \"text\": transformed_text,\n",
    "                    \"speaker\": utterance[\"speaker\"]\n",
    "                })\n",
    "            transformed_data.append(transformed_conversation)\n",
    "        return transformed_data\n",
    "\n",
    "    else: \n",
    "        for conversation in data:\n",
    "            transformed_conversation = {\n",
    "                \"conversation_ID\": conversation[\"conversation_ID\"],\n",
    "                \"conversation\": [],\n",
    "                \"emotion-cause_pairs\": conversation[\"emotion-cause_pairs\"]\n",
    "            }\n",
    "            fluency = {'neutral':'neutrally', 'joy':'joyfully', 'sadness':'sadly', 'anger':'angrily', 'fear':'fearfully', 'surprise':'surprisingly', 'disgust':'disgustingly'}\n",
    "            for utterance in conversation[\"conversation\"]:\n",
    "                transformed_text = f\"{utterance['speaker']} {fluency[utterance['emotion']]} said: {utterance['text']}\"\n",
    "                transformed_conversation[\"conversation\"].append({\n",
    "                    \"utterance_ID\": utterance[\"utterance_ID\"],\n",
    "                    \"text\": transformed_text,\n",
    "                    \"speaker\": utterance[\"speaker\"],\n",
    "                    \"emotion\": utterance[\"emotion\"]\n",
    "                })\n",
    "            transformed_data.append(transformed_conversation)\n",
    "    return transformed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sliding_padded_conversation_with_speaker_bio(conversation, num_padding=2, is_test = False): ## is_test == without_emotions\n",
    "    processed = []\n",
    "    conversation_texts = [utterance[\"text\"] for utterance in conversation[\"conversation\"]]\n",
    "    speakers = [utterance[\"speaker\"] for utterance in conversation[\"conversation\"]]\n",
    "    num_utterances = len(conversation_texts)\n",
    "    padding_token = \"[PAD]\"\n",
    "    emotion_causes = {}\n",
    "    \n",
    "    if not is_test:\n",
    "        for pair in conversation[\"emotion-cause_pairs\"]:\n",
    "            target_id, cause_text = pair[0].split(\"_\")[0], pair[1].split(\"_\")[1]\n",
    "            if target_id in emotion_causes:\n",
    "                emotion_causes[target_id].append(cause_text)\n",
    "            else:\n",
    "                emotion_causes[target_id] = [cause_text]\n",
    "\n",
    "    \n",
    "    for i in range(num_utterances):\n",
    "        utterance_id_str = str(conversation[\"conversation\"][i][\"utterance_ID\"])\n",
    "        left_context_text = ([padding_token] * num_padding + conversation_texts[:i+1])[-(num_padding+1):]\n",
    "        left_context_speakers = (['None'] * num_padding + speakers[:i+1])[-(num_padding+1):]\n",
    "        right_context_text = []\n",
    "        right_context_speakers = []\n",
    "\n",
    "        # right_context_text = (conversation_texts[i+1:] + [padding_token] * num_padding)[:num_padding]\n",
    "        # right_context_speakers = (speakers[i+1:] + ['None'] * num_padding)[:num_padding]\n",
    "        \n",
    "        context_parts = left_context_text + right_context_text\n",
    "        context_speakers = left_context_speakers + right_context_speakers\n",
    "        full_text = \" [SEP] \".join(context_parts)\n",
    "        full_speakers = []\n",
    "        \n",
    "        for part, speaker in zip(context_parts, context_speakers):\n",
    "            full_speakers.extend([speaker] * len(part.split()) + ['None'])\n",
    "        full_speakers.pop()\n",
    "        \n",
    "        tokens = full_text.split()\n",
    "        bio_tags = [\"O\"] * len(tokens)\n",
    "        \n",
    "        if not is_test:\n",
    "            if utterance_id_str in emotion_causes:\n",
    "                for cause in emotion_causes[utterance_id_str]:\n",
    "                    start_pos = full_text.find(cause)\n",
    "                    if start_pos != -1:\n",
    "                        cause_tokens = cause.split()\n",
    "                        start_index = len(full_text[:start_pos].split())\n",
    "                        end_index = start_index + len(cause_tokens)\n",
    "                        if start_index < len(bio_tags):\n",
    "                            bio_tags[start_index] = \"B\"\n",
    "                            for j in range(start_index + 1, end_index):\n",
    "                                if j < len(bio_tags):\n",
    "                                    bio_tags[j] = \"I\"\n",
    "        \n",
    "            processed.append({\n",
    "                \"conversation_ID\": conversation[\"conversation_ID\"],\n",
    "                \"utterance_ID\": conversation[\"conversation\"][i][\"utterance_ID\"],\n",
    "                \"padded_text\": full_text,\n",
    "                \"bio_tags\": bio_tags, \n",
    "                \"utterance_emotion\": conversation[\"conversation\"][i][\"emotion\"], \n",
    "                \"utterance_speaker\": conversation[\"conversation\"][i][\"speaker\"],\n",
    "                \"speakers_in_context\": full_speakers\n",
    "            })\n",
    "        \n",
    "        else:\n",
    "            processed.append({\n",
    "                \"conversation_ID\": conversation[\"conversation_ID\"],\n",
    "                \"utterance_ID\": conversation[\"conversation\"][i][\"utterance_ID\"],\n",
    "                \"padded_text\": full_text,\n",
    "                \"utterance_speaker\": conversation[\"conversation\"][i][\"speaker\"],\n",
    "                \"speakers_in_context\": full_speakers\n",
    "            })\n",
    "        \n",
    "    return processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved in train_file.json\n",
      "File saved in val_file.json\n",
      "File saved in test_file.json\n"
     ]
    }
   ],
   "source": [
    "def transform_json(input_file_path=\"Subtask_1_train.json\",output_file_path = \"train_final.json\", is_test = False) :\n",
    "    import json\n",
    "    data = []\n",
    "    with open(input_file_path, \"r\") as infile:\n",
    "        data = json.load(infile)\n",
    "\n",
    "    processed_data = transform_conversations(data, is_test = is_test)\n",
    "    data=processed_data\n",
    "\n",
    "    def process_full_dataset(dataset):\n",
    "        processed_dataset = []\n",
    "        for conversation in dataset:\n",
    "            processed_conversation = process_sliding_padded_conversation_with_speaker_bio(conversation, is_test = is_test)\n",
    "            processed_dataset.extend(processed_conversation)\n",
    "        return processed_dataset\n",
    "\n",
    "    full_dataset = data\n",
    "    processed_full_dataset = process_full_dataset(full_dataset)\n",
    "\n",
    "    with open(output_file_path, \"w\") as outfile:\n",
    "        json.dump(processed_full_dataset, outfile)\n",
    "\n",
    "    print(f\"File saved in {output_file_path}\")\n",
    "\n",
    "transform_json(\"train_file_normal.json\" , \"train_file.json\", is_test = False)\n",
    "transform_json(\"val_file_normal.json\" , \"val_file.json\", is_test = False)\n",
    "transform_json(\"Subtask_1_test.json\" , \"test_file.json\", is_test = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CPI_Dataset(Dataset):\n",
    "    def __init__(self, filename):\n",
    "        self.data = pd.read_json(filename)\n",
    "        self.tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "        self.sentence_encoder = SentenceTransformer('all-mpnet-base-v2')\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def get_new_labels(self, text, labels, speakers):\n",
    "        tokens = text.split()\n",
    "        new_labels = [0]\n",
    "        new_speakers = [\"None\"]\n",
    "\n",
    "        for word, label, speaker in zip(tokens, labels, speakers):\n",
    "            tokenised_word = self.tokenizer.tokenize(word)\n",
    "            n_subwords = len(tokenised_word)\n",
    "            if label == 'O':\n",
    "                new_labels.extend([0] * n_subwords)\n",
    "            elif label == 'B':\n",
    "                new_labels.append(1)\n",
    "                new_labels.extend([2] * (n_subwords - 1))\n",
    "            elif label == 'I':\n",
    "                new_labels.extend([2] * n_subwords)\n",
    "\n",
    "            new_speakers.extend([speaker] * n_subwords)\n",
    "\n",
    "        new_labels.append(0)\n",
    "        new_speakers.append(\"None\")\n",
    "        return new_labels, new_speakers\n",
    "        \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        sample =  self.data.iloc[idx]\n",
    "        text = sample['padded_text']\n",
    "        labels = sample['bio_tags']\n",
    "        speakers = sample['speakers_in_context']\n",
    "\n",
    "        sentences = text.split('[SEP]')\n",
    "        sentence_encoding = self.sentence_encoder.encode(sentences)\n",
    "\n",
    "        new_labels, new_speakers = self.get_new_labels(text, labels, speakers)\n",
    "\n",
    "        tokenized_text = self.tokenizer(text, return_tensors='pt')\n",
    "\n",
    "        return {\n",
    "            'input_ids': tokenized_text['input_ids'].squeeze(),\n",
    "            'attention_mask': tokenized_text['attention_mask'].squeeze(),\n",
    "            'labels': torch.tensor(new_labels),\n",
    "            'speakers': new_speakers,\n",
    "            'sentence_encoding': torch.tensor(sentence_encoding)\n",
    "        }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CPI(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CPI, self).__init__()\n",
    "        \n",
    "        self.window_size = 5\n",
    "\n",
    "        self.cross_attention = nn.MultiheadAttention(embed_dim=768, num_heads=1)\n",
    "\n",
    "        self.personality_dict = pkl.load(open(\"personality_dict.pkl\", \"rb\"))\n",
    "        self.personality_dict[\"None\"] = torch.zeros(1, 16)\n",
    "\n",
    "        self.bert = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.fully_connected = nn.Sequential(\n",
    "            nn.Linear(1552, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 3)\n",
    "        )\n",
    "\n",
    "    def personality_embedding(self, speaker):\n",
    "        speaker_personality_list = []\n",
    "        for i in speaker:\n",
    "            spk = i[0].lower()\n",
    "            if spk == 'none':\n",
    "                speaker_personality_list.append(torch.zeros(16).to(DEVICE))\n",
    "            else:\n",
    "                speaker_personality_list.append(self.personality_dict[spk][0])\n",
    "        \n",
    "        speaker_personality = torch.stack(speaker_personality_list).to(DEVICE)\n",
    "        speaker_personality = speaker_personality.unsqueeze(0)\n",
    "        return speaker_personality\n",
    "        \n",
    "\n",
    "    def forward(self, input_ids, attention_mask, speakers, sentence_encoding): \n",
    "\n",
    "        n = sentence_encoding.size(1)\n",
    "\n",
    "        ################ Sentence Tranformer #################\n",
    "\n",
    "        query = sentence_encoding[0][-1] # [1, 768]\n",
    "        query = query.repeat(sentence_encoding.size(1), 1) # [n, 768]\n",
    "        query = query.unsqueeze(0) # [1, n, 768]\n",
    "\n",
    "        key = sentence_encoding # [1, n, 768]\n",
    "        value = sentence_encoding # [1, n, 768]\n",
    "\n",
    "        attention_out, _ = self.cross_attention(query, key, value) # [1, n, 768]\n",
    "        # print(len(attention_out[0]))\n",
    "        idx = 0\n",
    "        attention_embd = [torch.zeros(768).to(DEVICE)]\n",
    "        for i in range(1, input_ids.size(1)-1):\n",
    "            if input_ids[0][i] == 102:\n",
    "                idx += 1\n",
    "            attention_embd.append(attention_out[0][idx])\n",
    "\n",
    "        attention_embd.append(torch.zeros(768).to(DEVICE))\n",
    "        \n",
    "        attention_out = torch.stack(attention_embd).to(DEVICE) # [n, 768]\n",
    "        attention_out = attention_out.unsqueeze(0) # [1, n, 768]\n",
    "\n",
    "        ################ Bert Tranformer #####################\n",
    "\n",
    "        outputs = self.bert(input_ids, attention_mask=attention_mask)\n",
    "        bert_embeddings = outputs.last_hidden_state\n",
    "\n",
    "        ################ Personality Embedding ###############\n",
    "\n",
    "        speaker_personality = self.personality_embedding(speakers)\n",
    "        # print(speaker_personality.size())\n",
    "\n",
    "        ################ Concatenation #######################\n",
    "\n",
    "        # print(bert_embeddings.size(), attention_out.size())\n",
    "\n",
    "        concatenated = torch.cat((bert_embeddings, attention_out, speaker_personality), dim=2) # [1, n, 1296]\n",
    "\n",
    "        ################ Fully Connected #####################\n",
    "\n",
    "        concatenated = concatenated.squeeze(0) # [n, 1296]\n",
    "        logits = self.fully_connected(concatenated) # [n, 3]\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop\n",
    "def train(model, train_loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in tqdm((train_loader)):\n",
    "        input_ids = batch['input_ids'].to(DEVICE)\n",
    "        attention_mask = batch['attention_mask'].to(DEVICE)\n",
    "        labels = batch['labels'].to(DEVICE)\n",
    "        speakers = batch['speakers']\n",
    "        sentence_encoding = batch['sentence_encoding'].to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(input_ids, attention_mask, speakers, sentence_encoding)\n",
    "        # print(logits.size(), labels.size())\n",
    "        # one hot encode the labels\n",
    "        labels = F.one_hot(labels, num_classes=3).to(DEVICE)\n",
    "        # print(logits.size(), labels.size())\n",
    "        loss = criterion(logits, labels.float()[0])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation Loop\n",
    "def validate(model, val_loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(val_loader):\n",
    "            input_ids = batch['input_ids'].to(DEVICE)\n",
    "            attention_mask = batch['attention_mask'].to(DEVICE)\n",
    "            labels = batch['labels'].to(DEVICE)\n",
    "            speakers = batch['speakers']\n",
    "            sentence_encoding = batch['sentence_encoding'].to(DEVICE)\n",
    "\n",
    "            logits = model(input_ids, attention_mask, speakers, sentence_encoding)\n",
    "            # print(logits.size(), labels.size())\n",
    "            labels = F.one_hot(labels, num_classes=3).to(DEVICE)\n",
    "            loss = criterion(logits, labels.float()[0])\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset = CPI_Dataset(\"train_file.json\")\n",
    "train_loader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "criteria = nn.CrossEntropyLoss().to(DEVICE)\n",
    "model = CPI().to(DEVICE)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "val_loader = DataLoader(CPI_Dataset(\"val_file.json\"), batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12297/12297 [03:13<00:00, 63.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Train Loss: 0.2710495908492666\n",
      "Val Loss: 0.2520995820349761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12297/12297 [03:07<00:00, 65.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Train Loss: 0.25203946084159634\n",
      "Val Loss: 0.29743411447497364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12297/12297 [03:17<00:00, 62.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Train Loss: 0.24590973634795324\n",
      "Val Loss: 0.24259852249808989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12297/12297 [03:11<00:00, 64.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Train Loss: 0.24246831561886834\n",
      "Val Loss: 0.2621877940193493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12297/12297 [03:10<00:00, 64.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Train Loss: 0.23869295327691115\n",
      "Val Loss: 0.2337415372369457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12297/12297 [03:21<00:00, 61.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Train Loss: 0.23739097046682292\n",
      "Val Loss: 0.23903007271528265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12297/12297 [03:15<00:00, 62.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Train Loss: 0.23376875761011262\n",
      "Val Loss: 0.23130775378952403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12297/12297 [03:14<00:00, 63.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Train Loss: 0.23215457117954702\n",
      "Val Loss: 0.2374322707768767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12297/12297 [03:18<00:00, 61.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Train Loss: 0.23058480095033973\n",
      "Val Loss: 0.23993796085764774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12297/12297 [03:16<00:00, 62.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Train Loss: 0.23287847913540263\n",
      "Val Loss: 0.23099659409960435\n"
     ]
    }
   ],
   "source": [
    "train_losses  , val_losses = [], []\n",
    "\n",
    "\n",
    "epoch = 0\n",
    "for i in range(epoch):\n",
    "    train_loss = train(model, train_loader, optimizer, criteria)\n",
    "    print(f\"Epoch {i} Train Loss: {train_loss}\")\n",
    "\n",
    "    val_loss = validate(model, val_loader, criteria)\n",
    "    print(f\"Val Loss: {val_loss}\")\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "\n",
    "    torch.save(model.state_dict(), f\"model_project2{i+1}.pt\")\n",
    "\n",
    "    pkl.dump(train_losses, open(\"train_losses.pkl\", \"wb\"))\n",
    "    pkl.dump(val_losses, open(\"val_losses.pkl\", \"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
